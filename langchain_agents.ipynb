{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python packages \n",
    "Installing prerequisites: langchain and langgraph libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure LLM\n",
    "\n",
    "Always run this, before trying out anything else. \n",
    "\n",
    "You can use OpenAI or AzureOpenAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE: Using AzureOpenAI instance as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = \"\"\n",
    "AZURE_OPENAI_API_KEY = \"\"\n",
    "AZURE_OPENAI_API_VERSION = \"2024-05-01-preview\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt4o\"\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE: Using OpenAI as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1 Tools, agentic workflows\n",
    "\n",
    "Scenario is a travel agent, who can manage travels (hotels, flights, car rentals). \n",
    "\n",
    "This is NOT a true agent prompt yet, only a chatbot that can execute tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock tools\n",
    "\n",
    "Ref: https://python.langchain.com/v0.2/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Non-sensitive tools (GET requests)\n",
    "\n",
    "@tool\n",
    "def mock_query_hotel_bookings(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about hotel bookings.\"\"\"\n",
    "\n",
    "    return \"Current bookings: 2 rooms booked for 3 nights each in Budapest.\"\n",
    "\n",
    "@tool\n",
    "def mock_query_flight_bookins(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about flight bookings.\"\"\"\n",
    "    return \"Current bookings: 2 flights booked to Budapest from Berlin.\"\n",
    "\n",
    "@tool\n",
    "def mock_query_car_rentals(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about car rentals.\"\"\"\n",
    "    return \"Current bookings: 1 car rented for 3 days in Budapest.\"\n",
    "\n",
    "# Sensitive tools (e.g. POST requests)\n",
    "\n",
    "@tool\n",
    "def mock_book_flight(user: str, origin: str, destination: str, date: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book flights.\"\"\"\n",
    "    return f\"Flight booked from {origin} to {destination} on {date}. Flight number is LH123 with Lufthansa.\"\n",
    "\n",
    "@tool\n",
    "def mock_book_hotel(user: str, city: str, checkin: str, checkout: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book hotels.\"\"\"\n",
    "    return f\"Hotel booked in {city} from {checkin} to {checkout}. Room number is 123.\"\n",
    "\n",
    "@tool\n",
    "def mock_book_car(user: str, city: str, date: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book cars.\"\"\"\n",
    "    return f\"Car rented in {city} on {date}. Car model is BMW 3 Series.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a simple tool selector chain\n",
    "\n",
    "Ref. https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I will check your flight bookings for you. Could you please provide me with your name or the user name under which the bookings were made?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "TOOL_SELECTOR_PROMPT_RAW = \"\"\"\n",
    "    You are part of a chat assistant that helps users with their travels.\n",
    "    If none of the available tools are useful, inform the user that you are NOT able to help.\n",
    "\n",
    "    Important: Always inform the user what is going to be done, especially during tool calls.\n",
    "    Always verify if you have all the necessary information to use the tool, otherwise ask the user first for the missing information.\n",
    "    You need to ask for user permission to use sensitive tools.\n",
    "\n",
    "    If the tool to be used is sensitive (as mentioned in its description), start your response with \"sensitive:\" in this case.\n",
    "    HOWEVER, only add \"sensitive:\" to response content when the exact tool is to be called, not during discussion or follow up questions or while asking for confirmation. \n",
    "    Also, don't include \"sensitive:\" in the response content if the tool to be called is not sensitive.\n",
    "    You cannot leave input parameters empty  or invalidt values for tool calls!! \n",
    "    \"\"\"\n",
    "\n",
    "tool_selector_prompt =  ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=TOOL_SELECTOR_PROMPT_RAW), \n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "]\n",
    ")\n",
    "\n",
    "plain_tools = [mock_query_hotel_bookings, mock_query_flight_bookins, mock_query_car_rentals]\n",
    "sensitive_tools = [mock_book_flight, mock_book_hotel, mock_book_car]\n",
    "all_tools = plain_tools + sensitive_tools\n",
    "llm = llm.bind_tools(all_tools)\n",
    "\n",
    "tool_chain = tool_selector_prompt | llm\n",
    "selector_response = tool_chain.invoke({\"input\": \"What flights do I have booked?\", \"history\" : []})\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how sensitive tools are called. \n",
    "\n",
    "You should also play with the system prompt. See what happens if you remove lines/instructions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from Helsinki to Budapest on January 1, 2023.\n",
      "\n",
      "Let's proceed with the booking.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_j9ICSjzLST5DrGxTrqtGhVkX)\n",
      " Call ID: call_j9ICSjzLST5DrGxTrqtGhVkX\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain.invoke({\"input\": \"Book me a flight from Helsinki to Budapest on 2023-01-01. My username is hegeduscs.\", \"history\" : []})\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add chat memory and test a simple agent flow\n",
    "\n",
    "Let's see how we can create a conversational chatbot with these tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///tool_agent_memory.db\")\n",
    "\n",
    "tool_chain_with_history = RunnableWithMessageHistory(\n",
    "    tool_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "tool_chain_with_history.get_session_history(\"1\").clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's see some actual chatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ae9f05dc-5e96-436d-82f8-a256fdebe83c not found for run f50817c2-8806-4f47-aa15-862d6ce536fd. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with booking a flight to Budapest for you. Could you please provide me with your current location (origin city) and your user information to proceed with the booking?\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": \"Book me a flight to Budapest on 2023-01-01.\"}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 8cc31486-a655-4af8-a299-c532e71d0afb not found for run 967cae96-44b1-4dbe-b34e-f4376b54ac53. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from Helsinki to Budapest on 2023-01-01.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_wkubXRnkCrKWjH2yB5QARaVj)\n",
      " Call ID: call_wkubXRnkCrKWjH2yB5QARaVj\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": \"hegeduscs and from Helsinki\"}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see full chat history so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest on 2023-01-01.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with booking a flight to Budapest for you. Could you please provide me with your current location (origin city) and your user information to proceed with the booking?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hegeduscs and from Helsinki\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from Helsinki to Budapest on 2023-01-01.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_wkubXRnkCrKWjH2yB5QARaVj)\n",
      " Call ID: call_wkubXRnkCrKWjH2yB5QARaVj\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "history = tool_chain_with_history.get_session_history(\"1\").get_messages()\n",
    "history_prompt = ChatPromptTemplate.from_messages(history)\n",
    "history_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to execute the tool call ourselves, and insert it into the history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mock_book_flight' description='This sensitive tool can be used to book flights.' args_schema=<class 'pydantic.v1.main.mock_book_flightSchema'> func=<function mock_book_flight at 0x0000026880F1E8E0>\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "content='Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.' tool_call_id='call_wkubXRnkCrKWjH2yB5QARaVj'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest on 2023-01-01.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with booking a flight to Budapest for you. Could you please provide me with your current location (origin city) and your user information to proceed with the booking?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hegeduscs and from Helsinki\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from Helsinki to Budapest on 2023-01-01.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_wkubXRnkCrKWjH2yB5QARaVj)\n",
      " Call ID: call_wkubXRnkCrKWjH2yB5QARaVj\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_to_call = selector_response.tool_calls[0][\"name\"].lower()\n",
    "selected_tool = next(tool for tool in all_tools if tool.name == tool_to_call)\n",
    "print(selected_tool)\n",
    "\n",
    "tool_output = selected_tool.invoke(input=selector_response.tool_calls[0][\"args\"])\n",
    "print(tool_output)\n",
    "\n",
    "tool_response = ToolMessage(content=tool_output, tool_call_id=selector_response.tool_calls[0][\"id\"])\n",
    "print(tool_response)\n",
    "\n",
    "#Be advised, adding this message to the history is not necessary here, we will invoke the model again with the tool response to get the next message\n",
    "tool_chain_with_history.get_session_history(\"1\").add_message(tool_response)\n",
    "\n",
    "#Let's see current chat history to see what's next\n",
    "history = tool_chain_with_history.get_session_history(\"1\").get_messages()\n",
    "history_prompt = ChatPromptTemplate.from_messages(history)\n",
    "history_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 9c9a2874-c625-430f-986a-7d43c183c0ae not found for run 5c80b963-9e5f-46d0-ace8-7e132d5e6a6f. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight from Helsinki to Budapest on 2023-01-01 has been successfully booked. The flight number is LH123 with Lufthansa.\n",
      "\n",
      "Is there anything else I can assist you with?\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": []}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 Langchain Agents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same but with Langchain/Langgraph agents. \n",
    "\n",
    "We are not getting into Langgraph deeply yet, just utilize simple agents from that library. The create_react_agent allows us to be very simple.  \n",
    "\n",
    "Scenario is the same, tools are same: travel assistant. \n",
    "\n",
    "**IMPORTANT**: run the tools section from above first. \n",
    "\n",
    "References: \n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/migrate_agent/#iterating-through-steps\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/prebuilt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the agent object, give it tools and a system prompt. The checkpointer is the chat memory (in memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What flights do I have booked?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_query_flight_bookins (call_QnTZj0YJa3VDmAPpZcEJbgfY)\n",
      " Call ID: call_QnTZj0YJa3VDmAPpZcEJbgfY\n",
      "  Args:\n",
      "    user: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_query_flight_bookins\n",
      "\n",
      "Current bookings: 2 flights booked to Budapest from Berlin.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You have 2 flights booked from Berlin to Budapest.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "AGENT_SYSTEM_PROMPT = SystemMessage(content=\"You are a travel assistant. You are asked to help the user with their travel plans.\")\n",
    "\n",
    "plain_tools = [mock_query_hotel_bookings, mock_query_flight_bookins, mock_query_car_rentals]\n",
    "sensitive_tools = [mock_book_flight, mock_book_hotel, mock_book_car]\n",
    "all_tools = plain_tools + sensitive_tools\n",
    "\n",
    "agent = create_react_agent(llm, all_tools, messages_modifier=AGENT_SYSTEM_PROMPT, checkpointer=MemorySaver())\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "input = {\"messages\": [(\"user\", \"What flights do I have booked?\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue the discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Could you please provide me with the following details for the flight booking:\n",
      "1. Departure city (if different from Berlin)\n",
      "2. Preferred date of travel\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [(\"user\", \"Book me a flight to Budapest\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "from Helsinki and on 2023-01-01\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_hGZXC0UM5sS8uzgoMva43du3)\n",
      " Call ID: call_hGZXC0UM5sS8uzgoMva43du3\n",
      "  Args:\n",
      "    user: user\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_book_flight\n",
      "\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight from Helsinki to Budapest on 2023-01-01 has been successfully booked. The flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [(\"user\", \"from Helsinki and on 2023-01-01\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print full history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What flights do I have booked?\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_query_flight_bookins (call_QnTZj0YJa3VDmAPpZcEJbgfY)\n",
      " Call ID: call_QnTZj0YJa3VDmAPpZcEJbgfY\n",
      "  Args:\n",
      "    user: user\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_query_flight_bookins\n",
      "\n",
      "Current bookings: 2 flights booked to Budapest from Berlin.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You have 2 flights booked from Berlin to Budapest.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Could you please provide me with the following details for the flight booking:\n",
      "1. Departure city (if different from Berlin)\n",
      "2. Preferred date of travel\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "from Helsinki and on 2023-01-01\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_hGZXC0UM5sS8uzgoMva43du3)\n",
      " Call ID: call_hGZXC0UM5sS8uzgoMva43du3\n",
      "  Args:\n",
      "    user: user\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_book_flight\n",
      "\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight from Helsinki to Budapest on 2023-01-01 has been successfully booked. The flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "state = agent.get_state(config)\n",
    "chat_history = state.values[\"messages\"]\n",
    "\n",
    "history_prompt = ChatPromptTemplate.from_messages(chat_history)\n",
    "history_prompt.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
