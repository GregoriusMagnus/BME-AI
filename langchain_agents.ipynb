{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python packages \n",
    "Installing prerequisites: langchain and langgraph libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure LLM\n",
    "\n",
    "Always run this, before trying out anything else. \n",
    "\n",
    "You can use OpenAI or AzureOpenAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE: Using AzureOpenAI instance as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = \"\"\n",
    "AZURE_OPENAI_API_KEY = \"\"\n",
    "AZURE_OPENAI_API_VERSION = \"2024-05-01-preview\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt4o\"\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE: Using OpenAI as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1 Tools, agentic workflows\n",
    "\n",
    "Scenario is a travel agent, who can manage travels (hotels, flights, car rentals). \n",
    "\n",
    "This is NOT a true agent prompt yet, only a chatbot that can execute tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock tools\n",
    "\n",
    "Ref: https://python.langchain.com/v0.2/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Non-sensitive tools (GET requests)\n",
    "\n",
    "@tool\n",
    "def mock_query_hotel_bookings(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about hotel bookings.\"\"\"\n",
    "\n",
    "    return \"Current bookings: 2 rooms booked for 3 nights each in Budapest.\"\n",
    "\n",
    "@tool\n",
    "def mock_query_flight_bookins(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about flight bookings.\"\"\"\n",
    "    return \"Current bookings: 2 flights booked to Budapest from Berlin.\"\n",
    "\n",
    "@tool\n",
    "def mock_query_car_rentals(user: str) -> str:\n",
    "    \"\"\"This tool can be used to fetch information about car rentals.\"\"\"\n",
    "    return \"Current bookings: 1 car rented for 3 days in Budapest.\"\n",
    "\n",
    "# Sensitive tools (e.g. POST requests)\n",
    "\n",
    "@tool\n",
    "def mock_book_flight(user: str, origin: str, destination: str, date: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book flights.\"\"\"\n",
    "    return f\"Flight booked from {origin} to {destination} on {date}. Flight number is LH123 with Lufthansa.\"\n",
    "\n",
    "@tool\n",
    "def mock_book_hotel(user: str, city: str, checkin: str, checkout: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book hotels.\"\"\"\n",
    "    return f\"Hotel booked in {city} from {checkin} to {checkout}. Room number is 123.\"\n",
    "\n",
    "@tool\n",
    "def mock_book_car(user: str, city: str, date: str) -> str:\n",
    "    \"\"\"This sensitive tool can be used to book cars.\"\"\"\n",
    "    return f\"Car rented in {city} on {date}. Car model is BMW 3 Series.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a simple tool selector chain\n",
    "\n",
    "Ref. https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll check your flight bookings for you. Could you please provide me with your username so I can look up the information?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "TOOL_SELECTOR_PROMPT_RAW = \"\"\"\n",
    "    You are part of a chat assistant that helps users with their travels.\n",
    "    If none of the available tools are useful, inform the user that you are NOT able to help.\n",
    "\n",
    "    Important: Always inform the user what is going to be done, especially during tool calls.\n",
    "    Always verify if you have all the necessary information to use the tool, otherwise ask the user first for the missing information.\n",
    "    You need to ask for user permission to use sensitive tools.\n",
    "\n",
    "    If the tool to be used is sensitive (as mentioned in its description), start your response with \"sensitive:\" in this case.\n",
    "    HOWEVER, only add \"sensitive:\" to response content when the exact tool is to be called, not during discussion or follow up questions or while asking for confirmation. \n",
    "    Also, don't include \"sensitive:\" in the response content if the tool to be called is not sensitive.\n",
    "    You cannot leave input parameters empty  or invalidt values for tool calls!! \n",
    "    \"\"\"\n",
    "\n",
    "tool_selector_prompt =  ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=TOOL_SELECTOR_PROMPT_RAW), \n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "]\n",
    ")\n",
    "\n",
    "plain_tools = [mock_query_hotel_bookings, mock_query_flight_bookins, mock_query_car_rentals]\n",
    "sensitive_tools = [mock_book_flight, mock_book_hotel, mock_book_car]\n",
    "all_tools = plain_tools + sensitive_tools\n",
    "llm = llm.bind_tools(all_tools)\n",
    "\n",
    "tool_chain = tool_selector_prompt | llm\n",
    "selector_response = tool_chain.invoke({\"input\": \"What flights do I have booked?\", \"history\" : []})\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how sensitive tools are called. \n",
    "\n",
    "You should also play with the system prompt. See what happens if you remove lines/instructions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sensitive: I will now proceed with booking a flight from Helsinki to Budapest on 2023-01-01 for user hegeduscs.\n",
      "\n",
      "Let's proceed with the booking.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_vOg714Fq6KDgBGjKxeVDVXOm)\n",
      " Call ID: call_vOg714Fq6KDgBGjKxeVDVXOm\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain.invoke({\"input\": \"Book me a flight from Helsinki to Budapest on 2023-01-01. My username is hegeduscs. Proceed with the booking.\", \"history\" : []})\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add chat memory and test a simple agent flow\n",
    "\n",
    "Let's see how we can create a conversational chatbot with these tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, connection=\"sqlite:///tool_agent_memory.db\")\n",
    "\n",
    "tool_chain_with_history = RunnableWithMessageHistory(\n",
    "    tool_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "tool_chain_with_history.get_session_history(\"1\").clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's see some actual chatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help you with booking the flight. I will need your username to proceed with the booking. Could you please provide it?\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": \"Book me a flight to Budapest on 2023-01-01.\"}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from your origin city to Budapest on 2023-01-01.\n",
      "\n",
      "Let's proceed with the booking.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_rLn3BXNXCLICPFyHvC7evRqV)\n",
      " Call ID: call_rLn3BXNXCLICPFyHvC7evRqV\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: \n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": \"hegeduscs is the username\"}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see full chat history so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest on 2023-01-01.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help you with booking the flight. I will need your username to proceed with the booking. Could you please provide it?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hegeduscs is the username\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from your origin city to Budapest on 2023-01-01.\n",
      "\n",
      "Let's proceed with the booking.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_rLn3BXNXCLICPFyHvC7evRqV)\n",
      " Call ID: call_rLn3BXNXCLICPFyHvC7evRqV\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: \n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "history = tool_chain_with_history.get_session_history(\"1\").get_messages()\n",
    "history_prompt = ChatPromptTemplate.from_messages(history)\n",
    "history_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to execute the tool call ourselves, and insert it into the history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mock_book_flight' description='This sensitive tool can be used to book flights.' args_schema=<class 'langchain_core.utils.pydantic.mock_book_flight'> func=<function mock_book_flight at 0x0000028504827740>\n",
      "Flight booked from  to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "content='Flight booked from  to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.' tool_call_id='call_rLn3BXNXCLICPFyHvC7evRqV'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest on 2023-01-01.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help you with booking the flight. I will need your username to proceed with the booking. Could you please provide it?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hegeduscs is the username\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "sensitive: I will now proceed to book a flight for you from your origin city to Budapest on 2023-01-01.\n",
      "\n",
      "Let's proceed with the booking.\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_rLn3BXNXCLICPFyHvC7evRqV)\n",
      " Call ID: call_rLn3BXNXCLICPFyHvC7evRqV\n",
      "  Args:\n",
      "    user: hegeduscs\n",
      "    origin: \n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Flight booked from  to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_to_call = selector_response.tool_calls[0][\"name\"].lower()\n",
    "selected_tool = next(tool for tool in all_tools if tool.name == tool_to_call)\n",
    "print(selected_tool)\n",
    "\n",
    "tool_output = selected_tool.invoke(input=selector_response.tool_calls[0][\"args\"])\n",
    "print(tool_output)\n",
    "\n",
    "tool_response = ToolMessage(content=tool_output, tool_call_id=selector_response.tool_calls[0][\"id\"])\n",
    "print(tool_response)\n",
    "\n",
    "#Be advised, adding this message to the history is not necessary here, we will invoke the model again with the tool response to get the next message\n",
    "tool_chain_with_history.get_session_history(\"1\").add_message(tool_response)\n",
    "\n",
    "#Let's see current chat history to see what's next\n",
    "history = tool_chain_with_history.get_session_history(\"1\").get_messages()\n",
    "history_prompt = ChatPromptTemplate.from_messages(history)\n",
    "history_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight to Budapest on 2023-01-01 has been successfully booked. Here are the details:\n",
      "\n",
      "- **Flight Number:** LH123\n",
      "- **Airline:** Lufthansa\n",
      "\n",
      "Safe travels! If you need any further assistance, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "selector_response = tool_chain_with_history.invoke({\"input\": []}, config={\"configurable\": {\"session_id\": \"1\"}},)\n",
    "selector_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 Langchain Agents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same but with Langchain/Langgraph agents. \n",
    "\n",
    "We are not getting into Langgraph deeply yet, just utilize simple agents from that library. The create_react_agent allows us to be very simple.  \n",
    "\n",
    "Scenario is the same, tools are same: travel assistant. \n",
    "\n",
    "**IMPORTANT**: run the tools section from above first. \n",
    "\n",
    "References: \n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/migrate_agent/#iterating-through-steps\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/prebuilt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the agent object, give it tools and a system prompt. The checkpointer is the chat memory (in memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heged\\AppData\\Local\\Temp\\ipykernel_10036\\1573013232.py:11: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.3.0. Use 'state_modifier' parameter instead.\n",
      "  agent = create_react_agent(llm, all_tools, messages_modifier=AGENT_SYSTEM_PROMPT, checkpointer=MemorySaver())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What flights do I have booked?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_query_flight_bookins (call_ALGYtZzQuAh8OExLwYHB4g6m)\n",
      " Call ID: call_ALGYtZzQuAh8OExLwYHB4g6m\n",
      "  Args:\n",
      "    user: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_query_flight_bookins\n",
      "\n",
      "Current bookings: 2 flights booked to Budapest from Berlin.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You have 2 flights booked to Budapest from Berlin.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "AGENT_SYSTEM_PROMPT = SystemMessage(content=\"You are a travel assistant. You are asked to help the user with their travel plans.\")\n",
    "\n",
    "plain_tools = [mock_query_hotel_bookings, mock_query_flight_bookins, mock_query_car_rentals]\n",
    "sensitive_tools = [mock_book_flight, mock_book_hotel, mock_book_car]\n",
    "all_tools = plain_tools + sensitive_tools\n",
    "\n",
    "agent = create_react_agent(llm, all_tools, messages_modifier=AGENT_SYSTEM_PROMPT, checkpointer=MemorySaver())\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "input = {\"messages\": [(\"user\", \"What flights do I have booked?\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue the discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Could you please provide the departure city and the desired travel date for your flight to Budapest?\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [(\"user\", \"Book me a flight to Budapest\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "from Helsinki and on 2023-01-01\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_kZOfY9C5BA8Q6wMApjIiYbd9)\n",
      " Call ID: call_kZOfY9C5BA8Q6wMApjIiYbd9\n",
      "  Args:\n",
      "    user: user\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_book_flight\n",
      "\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight from Helsinki to Budapest on 2023-01-01 has been successfully booked. Your flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [(\"user\", \"from Helsinki and on 2023-01-01\")]}\n",
    "\n",
    "for s in agent.stream(input, config, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print full history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What flights do I have booked?\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_query_flight_bookins (call_ALGYtZzQuAh8OExLwYHB4g6m)\n",
      " Call ID: call_ALGYtZzQuAh8OExLwYHB4g6m\n",
      "  Args:\n",
      "    user: user\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_query_flight_bookins\n",
      "\n",
      "Current bookings: 2 flights booked to Budapest from Berlin.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You have 2 flights booked to Budapest from Berlin.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Book me a flight to Budapest\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Could you please provide the departure city and the desired travel date for your flight to Budapest?\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "from Helsinki and on 2023-01-01\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mock_book_flight (call_kZOfY9C5BA8Q6wMApjIiYbd9)\n",
      " Call ID: call_kZOfY9C5BA8Q6wMApjIiYbd9\n",
      "  Args:\n",
      "    user: user\n",
      "    origin: Helsinki\n",
      "    destination: Budapest\n",
      "    date: 2023-01-01\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mock_book_flight\n",
      "\n",
      "Flight booked from Helsinki to Budapest on 2023-01-01. Flight number is LH123 with Lufthansa.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your flight from Helsinki to Budapest on 2023-01-01 has been successfully booked. Your flight number is LH123 with Lufthansa.\n"
     ]
    }
   ],
   "source": [
    "state = agent.get_state(config)\n",
    "chat_history = state.values[\"messages\"]\n",
    "\n",
    "history_prompt = ChatPromptTemplate.from_messages(chat_history)\n",
    "history_prompt.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
